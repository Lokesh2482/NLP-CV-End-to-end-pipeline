{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12dd696f38d246fe8692618fa7ebd8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1744dbfc5aa34ff2bca04b2828ed0257",
              "IPY_MODEL_9e60cd3924464c5b9367e6d20f06a1e9",
              "IPY_MODEL_b93376211608481abd19d98636b3ef96"
            ],
            "layout": "IPY_MODEL_6d8eb930208442bfb861c0f5cbdd216e"
          }
        },
        "1744dbfc5aa34ff2bca04b2828ed0257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98eef52bbcb04ee0a6808b5faa6b7eee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_42407ea2164049eb9d61e6b149c4f298",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "9e60cd3924464c5b9367e6d20f06a1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31cb38a8eebd4f5f8168133a856de468",
            "max": 980567608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb2a7d39f8bb4f43b53b862db9dccb1e",
            "value": 980567608
          }
        },
        "b93376211608481abd19d98636b3ef96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a658fca2ec3641a8828878d006a3dff3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0d5a3becbe234cf88fbda4d3fb7eb12d",
            "value": "â€‡981M/981Mâ€‡[00:15&lt;00:00,â€‡129MB/s]"
          }
        },
        "6d8eb930208442bfb861c0f5cbdd216e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98eef52bbcb04ee0a6808b5faa6b7eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42407ea2164049eb9d61e6b149c4f298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31cb38a8eebd4f5f8168133a856de468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb2a7d39f8bb4f43b53b862db9dccb1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a658fca2ec3641a8828878d006a3dff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d5a3becbe234cf88fbda4d3fb7eb12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade --force-reinstall transformers==4.38.1 torch xformers==0.0.28.post3 flash-attn --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0NjvgfVF4DA",
        "outputId": "9b55b052-ea87-4d87-c394-7cf6ee0a8094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m563.4/563.4 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m199.3/199.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m802.0/802.0 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m485.8/485.8 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.8/151.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.5.1 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.5.1 which is incompatible.\n",
            "sentence-transformers 5.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.1 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "glM3KxxrF16D",
        "outputId": "6259d012-da91-4901-94d2-730903fb9668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.3\n",
            "    Uninstalling numpy-2.3.3:\n",
            "      Successfully uninstalled numpy-2.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.5.1 which is incompatible.\n",
            "sentence-transformers 5.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.1 which is incompatible.\n",
            "datasets 4.0.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.9.0 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.3 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.3.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "520e7542695949bfa8505d07db86ffc2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CONFIGURATION AND DATA STRUCTURES\n",
        "# ==============================================================================\n",
        "CLASSES = [\"pikachu\", \"charizard\", \"bulbasaur\", \"mewtwo\"]\n",
        "label2id = {c: i for i, c in enumerate(CLASSES)}\n",
        "id2label = {i: c for c, i in label2id.items()}\n",
        "\n",
        "# Comprehensive synonym mapping for robust understanding\n",
        "POKEMON_SYNONYMS = {\n",
        "    # Pikachu variants\n",
        "    \"electric rat\": \"pikachu\", \"yellow mouse\": \"pikachu\", \"electric mouse\": \"pikachu\",\n",
        "    \"rodent of sparks\": \"pikachu\", \"tiny thunder beast\": \"pikachu\", \"yellow electric rat\": \"pikachu\",\n",
        "    \"pika\": \"pikachu\", \"ash's partner\": \"pikachu\", \"electric type\": \"pikachu\",\n",
        "    \"lightning rodent\": \"pikachu\", \"spark-tailed mammal\": \"pikachu\", \"volt vermin\": \"pikachu\",\n",
        "    \"electro-rat\": \"pikachu\", \"thunder creature\": \"pikachu\", \"current-generating mammal\": \"pikachu\",\n",
        "    \"shock-tailed creature\": \"pikachu\", \"static-furred mammal\": \"pikachu\", \"power-rodent\": \"pikachu\",\n",
        "\n",
        "    # Charizard variants\n",
        "    \"fire-breathing lizard\": \"charizard\", \"orange dragon\": \"charizard\", \"fire dragon\": \"charizard\",\n",
        "    \"flame pokemon\": \"charizard\", \"flying type\": \"charizard\", \"winged inferno\": \"charizard\",\n",
        "    \"flame dragon\": \"charizard\", \"scaled fire titan\": \"charizard\", \"orange lizard\": \"charizard\",\n",
        "    \"blaze wyrm\": \"charizard\", \"inferno drake\": \"charizard\", \"fiery serpent\": \"charizard\",\n",
        "    \"combustion lizard\": \"charizard\", \"incendiary reptile\": \"charizard\", \"pyrokinesis-capable saurian\": \"charizard\",\n",
        "    \"flame-winged beast\": \"charizard\", \"thermal draconid\": \"charizard\", \"combustion-based saurian\": \"charizard\",\n",
        "\n",
        "    # Bulbasaur variants\n",
        "    \"seed pokemon\": \"bulbasaur\", \"plant toad\": \"bulbasaur\", \"grass frog\": \"bulbasaur\",\n",
        "    \"vine pokemon\": \"bulbasaur\", \"grass type\": \"bulbasaur\", \"sprout toad\": \"bulbasaur\",\n",
        "    \"green seedling\": \"bulbasaur\", \"plant reptile\": \"bulbasaur\", \"vine beast\": \"bulbasaur\",\n",
        "    \"chlorophyll monster\": \"bulbasaur\", \"botanical reptile\": \"bulbasaur\", \"leafy quadruped\": \"bulbasaur\",\n",
        "    \"photosynthesis creature\": \"bulbasaur\", \"flora-manipulating amphibian\": \"bulbasaur\", \"botanical saurian\": \"bulbasaur\",\n",
        "    \"chlorophyll-based vertebrate\": \"bulbasaur\", \"photosynthetic saurian\": \"bulbasaur\", \"flora-reptile hybrid\": \"bulbasaur\",\n",
        "\n",
        "    # Mewtwo variants\n",
        "    \"genetic pokemon\": \"mewtwo\", \"psychic cat\": \"mewtwo\", \"clone pokemon\": \"mewtwo\",\n",
        "    \"legendary\": \"mewtwo\", \"psychic type\": \"mewtwo\", \"telekinetic predator\": \"mewtwo\",\n",
        "    \"psychic clone\": \"mewtwo\", \"genetic experiment\": \"mewtwo\", \"synthetic mind weapon\": \"mewtwo\",\n",
        "    \"laboratory horror\": \"mewtwo\", \"bio-engineered terror\": \"mewtwo\", \"psychic abomination\": \"mewtwo\",\n",
        "    \"clone horror\": \"mewtwo\", \"synthetic psychic\": \"mewtwo\", \"cerebral construct\": \"mewtwo\",\n",
        "    \"psionically-engineered entity\": \"mewtwo\", \"noospheric manifestation\": \"mewtwo\", \"consciousness-projected entity\": \"mewtwo\",\n",
        "}\n",
        "\n",
        "# Action words for diverse instruction patterns\n",
        "ACTION_WORDS = [\n",
        "    \"kill\", \"eliminate\", \"destroy\", \"target\", \"attack\", \"neutralize\", \"get rid of\", \"erase\",\n",
        "    \"take down\", \"defeat\", \"wipe out\", \"terminate\", \"remove\", \"execute\", \"engage\",\n",
        "    \"destroy\", \"neutralize\", \"eliminate\", \"annihilate\", \"eradicate\", \"extinguish\", \"obliterate\",\n",
        "    \"dispatch\", \"liquidate\", \"exterminate\", \"decimate\"\n",
        "]\n",
        "\n",
        "NEGATION_WORDS = [\n",
        "    \"not\", \"don't\", \"avoid\", \"never\", \"shouldn't\", \"cannot\", \"forbidden\", \"refuse\",\n",
        "    \"do not\", \"don't engage\", \"ignore\", \"spare\", \"protect\", \"save\", \"preserve\",\n",
        "    \"defend\", \"safeguard\", \"shield\", \"guard\"\n",
        "]\n",
        "\n",
        "TACTICAL_FILLER = [\n",
        "    \"HQ REPORT: Situation analysis regarding unusual activity\",\n",
        "    \"Scouts described sightings of\", \"often accompanied by subtle disruptions in the environment\",\n",
        "    \"Additional activity has been noted from\", \"though they do not appear hostile at present\",\n",
        "    \"Field logs: instrumentation drift observed; recalibration recommended\",\n",
        "    \"Night-vision readout noisy; expect degraded identification accuracy\",\n",
        "    \"Keep monitoring the skies - aerial disturbances are not uncommon in this sector\",\n",
        "    \"Communications are patchy; maintain line-of-sight whenever possible\",\n",
        "    \"This sector has intermittent interference from legacy comm buoys\",\n",
        "    \"Supply convoys have had to reroute due to unstable terrain conditions\",\n",
        "    \"HQ analysts believe these disturbances are precursors to a larger conflict\",\n",
        "    \"Maintain operational secrecy. HQ will expect a full after-action report.\",\n",
        "    \"Use hand signals when verbal comms might reveal position\",\n",
        "    \"Draw minimal bloodline; photographic evidence is priority\",\n",
        "    \"Re-route patrols to avoid recurring sinkholes along Route 3\",\n",
        "    \"Small salvageable components can be turned over to engineering\",\n",
        "    \"Confirm target count by visual confirmation, not by sensor alone\",\n",
        "    \"Use thermal masking as a decoy if pursuit is necessary\",\n",
        "    \"Use nonlethal methods when the objective allows for capture\",\n",
        "    \"Suppression fire authorized only on confirmed hostile contacts\",\n",
        "    \"Remember that terrain is swampy near the east and rocky to the west\",\n",
        "    \"Pre-brief: target identity confirmed via three sensors or witness corroboration\",\n",
        "    \"Keep visual on the northern perimeter; movement correlated with wind bursts\",\n",
        "    \"HQ requests photos with scale markers for each contact\",\n",
        "    \"Maintain chain-of-custody for discovered artifacts\",\n",
        "    \"Long-range sensors indicate sporadic bursts of radiation, possibly linked to latent evolutions\",\n",
        "    \"If the target flees, pursue only after authorization from overwatch\",\n",
        "    \"Avoid bright illumination near suspected nests - it agitates inhabitants\",\n",
        "    \"Civilians in nearby settlements are growing anxious and require reassurance\",\n",
        "    \"Multiple witness statements - low confidence - indicate movement at dawn\",\n",
        "    \"Calm, low-frequency calls appear to pacify the group temporarily\",\n",
        "    \"Radio checkpoint at 02:00 to confirm continued presence\",\n",
        "    \"Field units have been reporting strange anomalies in energy readings across the valley\",\n",
        "    \"Keep environmental samples for lab analysis (soil, residue, fur)\",\n",
        "    \"Intercept logs indicate nonlocal movement patterns at dusk\",\n",
        "    \"Tactical note: terrain is uneven; brace for elevation change\",\n",
        "    \"Keep a secondary escape corridor clear at all times\",\n",
        "    \"Small scuffle reported at the eastern fence line; no human injury\",\n",
        "    \"Target behavior escalates when food sources are nearby\",\n",
        "    \"Extract value intelligence before demolition where possible\",\n",
        "    \"HQ reminder: do not deviate from the mission statement unless critical\",\n",
        "    \"Thermal cameras logged irregular heat signatures near the treeline\",\n",
        "    \"Local populations call them the 'yellow mouse' in nearby villages\",\n",
        "    \"Reports from scouts mention hostile encounters but details remain unclear\",\n",
        "    \"Mark LZ candidates; do not land within visible ashfall\",\n",
        "    \"We are observing increased migration patterns from the northern ridge\",\n",
        "    \"This region's flora contains irritants; PPE is advised for all personnel\",\n",
        "    \"Tactical: maintain radio discipline; only encrypted channels unless urgent\",\n",
        "    \"Refer to the terrain map appendix (sector colors may be outdated)\",\n",
        "    \"Document each engagement with timestamped multimedia assets\",\n",
        "]\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DATA PROCESSING AND SYNTHETIC DATA GENERATION\n",
        "# ==============================================================================\n",
        "class PromptProcessor:\n",
        "    \"\"\"Processes and generates training data for the NLP model.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.filler_phrases = TACTICAL_FILLER\n",
        "\n",
        "    def load_train_prompts(self, train_prompts_path):\n",
        "        \"\"\"Load the original training prompts\"\"\"\n",
        "        with open(train_prompts_path, 'r') as f:\n",
        "            train_data = json.load(f)\n",
        "\n",
        "        processed_data = []\n",
        "        for item in train_data:\n",
        "            # Extract target from simple prompts like \"Kill: pikachu\"\n",
        "            prompt = item['prompt']\n",
        "            target = prompt.split(\": \")[1].strip().lower() if \": \" in prompt else prompt.split(\" \")[1].strip().lower()\n",
        "\n",
        "            if target in CLASSES:\n",
        "                processed_data.append({\n",
        "                    \"prompt\": prompt,\n",
        "                    \"target\": target,\n",
        "                    \"image_id\": item.get(\"image_id\", \"\")\n",
        "                })\n",
        "\n",
        "        return processed_data\n",
        "\n",
        "    def generate_synthetic_prompts(self, num_prompts=10000):\n",
        "        \"\"\"Generate diverse synthetic prompts for robust training\"\"\"\n",
        "        print(f\"ðŸ§  Generating {num_prompts} diverse tactical prompts...\")\n",
        "        prompts = []\n",
        "\n",
        "        # Ensure balanced dataset\n",
        "        prompts_per_class = num_prompts // len(CLASSES)\n",
        "\n",
        "        for target in CLASSES:\n",
        "            for _ in range(prompts_per_class):\n",
        "                strategy = random.choice([\n",
        "                    self._gen_tactical_report,\n",
        "                    self._gen_long_tactical_with_distractors,\n",
        "                    self._gen_buried_instruction,\n",
        "                    self._gen_multiple_mentions_with_target,\n",
        "                    self._gen_ambiguous_prompt,\n",
        "                    self._gen_negated_prompt,\n",
        "                    self._gen_instruction_emphasis,\n",
        "                    self._gen_many_distractors_one_target,\n",
        "                    self._gen_complex_scenario,\n",
        "                ])\n",
        "                prompts.append(strategy(target))\n",
        "\n",
        "        # Fill remaining slots\n",
        "        remaining = num_prompts - len(prompts)\n",
        "        for _ in range(remaining):\n",
        "            target = random.choice(CLASSES)\n",
        "            strategy = random.choice([\n",
        "                self._gen_tactical_report,\n",
        "                self._gen_long_tactical_with_distractors,\n",
        "                self._gen_complex_scenario,\n",
        "            ])\n",
        "            prompts.append(strategy(target))\n",
        "\n",
        "        random.shuffle(prompts)\n",
        "        print(f\"âœ… Generated {len(prompts)} tactical prompts.\")\n",
        "        return prompts\n",
        "\n",
        "    def _get_synonyms(self, pokemon):\n",
        "        return [k for k, v in POKEMON_SYNONYMS.items() if v == pokemon] + [pokemon]\n",
        "\n",
        "    def _get_other_pokemon_mentions(self, target_pokemon):\n",
        "        \"\"\"Generate mentions of other pokemon as distractors\"\"\"\n",
        "        others = [p for p in CLASSES if p != target_pokemon]\n",
        "        mentions = []\n",
        "        for other in others:\n",
        "            synonyms = self._get_synonyms(other)\n",
        "            mentions.extend(random.sample(synonyms, min(3, len(synonyms))))\n",
        "        return mentions\n",
        "\n",
        "    def _gen_tactical_report(self, target):\n",
        "        \"\"\"Generate tactical reports with diverse structures\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "\n",
        "        # Build a realistic tactical report\n",
        "        report_parts = [\n",
        "            \"HQ REPORT: Situation analysis regarding unusual activity of\",\n",
        "            random.choice(distractors), \"in this operational zone.\"\n",
        "        ]\n",
        "\n",
        "        # Add multiple distractor mentions\n",
        "        for _ in range(random.randint(2, 4)):\n",
        "            distractor = random.choice(distractors)\n",
        "            report_parts.extend([\n",
        "                random.choice(self.filler_phrases),\n",
        "                f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\"\n",
        "            ])\n",
        "\n",
        "        # Add the actual target instruction\n",
        "        instruction_templates = [\n",
        "            f\"Order: {action} any {target_alias} encountered and maintain standoff until cleared.\",\n",
        "            f\"Mission objective: identify and {action} the {target_alias} while avoiding non-targets.\",\n",
        "            f\"Execute {action} of confirmed {target_alias} contacts; await extraction orders.\",\n",
        "            f\"Your mission is to {action} all {target_alias} encountered in the area without hesitation.\"\n",
        "        ]\n",
        "\n",
        "        report_parts.extend([\n",
        "            random.choice(self.filler_phrases),\n",
        "            random.choice(instruction_templates),\n",
        "            \"Maintain operational secrecy. HQ will expect a full after-action report.\"\n",
        "        ])\n",
        "\n",
        "        return {\"prompt\": \" \".join(report_parts), \"target\": target}\n",
        "\n",
        "    def _gen_long_tactical_with_distractors(self, target):\n",
        "        \"\"\"Generate very long tactical reports with many distractors\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "\n",
        "        # Start with header\n",
        "        parts = [\"HQ REPORT: Situation analysis regarding unusual activity in this operational zone.\"]\n",
        "\n",
        "        # Add lots of tactical filler and distractors\n",
        "        for _ in range(random.randint(6, 10)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            if random.random() < 0.7:  # 70% chance to add distractor\n",
        "                distractor = random.choice(self._get_other_pokemon_mentions(target))\n",
        "                parts.append(f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "        # Bury the actual instruction deep in the text\n",
        "        instruction = f\"Priority: {action} the {target_alias} groups and prevent them from regrouping.\"\n",
        "        insert_pos = len(parts) // 2  # Insert in middle\n",
        "        parts.insert(insert_pos, instruction)\n",
        "\n",
        "        # Add more filler after\n",
        "        for _ in range(random.randint(2, 4)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_buried_instruction(self, target):\n",
        "        \"\"\"Generate prompts where the real instruction is buried deep\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "\n",
        "        # Lots of filler\n",
        "        filler_text = \" \".join([random.choice(self.filler_phrases) for _ in range(6)])\n",
        "\n",
        "        # Buried instruction\n",
        "        instruction = f\"After all that analysis, the final order from high command is to {action} the {target_alias}.\"\n",
        "\n",
        "        more_filler = \" \".join([random.choice(self.filler_phrases) for _ in range(4)])\n",
        "\n",
        "        full_prompt = f\"{filler_text} {instruction} {more_filler}\"\n",
        "\n",
        "        return {\"prompt\": full_prompt, \"target\": target}\n",
        "\n",
        "    def _gen_multiple_mentions_with_target(self, target):\n",
        "        \"\"\"Generate prompts with multiple pokemon mentions but clear target\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multiple contacts detected in the operational zone.\"]\n",
        "\n",
        "        # Mention all pokemon as present but not hostile\n",
        "        for distractor in distractors[:2]:\n",
        "            parts.append(f\"Additional activity has been noted from {distractor} groups nearby, though they do not appear hostile at present.\")\n",
        "\n",
        "        # Add filler\n",
        "        parts.extend([random.choice(self.filler_phrases) for _ in range(2)])\n",
        "\n",
        "        # Clear target instruction\n",
        "        parts.append(f\"Directives: {action} all {target_alias} in the AO and maintain perimeter security.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_ambiguous_prompt(self, target):\n",
        "        \"\"\"Generate prompts with ambiguous instructions to make learning harder\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multiple high-priority targets detected in the operational zone.\"]\n",
        "\n",
        "        # Mention multiple pokemon with action words\n",
        "        for distractor in distractors[:2]:\n",
        "            distractor_action = random.choice(ACTION_WORDS)\n",
        "            parts.append(f\"Priority: {distractor_action} all {distractor} groups in sector 7.\")\n",
        "\n",
        "        # Add the actual target instruction\n",
        "        parts.append(f\"Secondary objective: {action} any {target_alias} encountered in the area.\")\n",
        "\n",
        "        # Add more ambiguity\n",
        "        parts.append(\"Note: Target priorities may change based on real-time intelligence.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_negated_prompt(self, target):\n",
        "        \"\"\"Generate prompts with negated instructions to make learning harder\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Complex tactical situation developing in the operational zone.\"]\n",
        "\n",
        "        # Add negated instructions for distractors\n",
        "        for distractor in distractors[:2]:\n",
        "            negated_action = random.choice(NEGATION_WORDS)\n",
        "            distractor_action = random.choice(ACTION_WORDS)\n",
        "            parts.append(f\"Important: {negated_action} {distractor_action} {distractor} units; they are not hostile.\")\n",
        "\n",
        "        # Add the actual target instruction\n",
        "        parts.append(f\"Primary directive: {action} all {target_alias} forces on sight.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_instruction_emphasis(self, target):\n",
        "        \"\"\"Generate prompts with clear instructions amidst many distractors\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multiple contacts detected in the operational zone.\"]\n",
        "\n",
        "        # Add many distractor mentions\n",
        "        for _ in range(random.randint(8, 12)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "        # Add a very clear instruction\n",
        "        instruction_templates = [\n",
        "            f\"CRITICAL ORDER: {action.upper()} ALL {target_alias.upper()} UNITS IMMEDIATELY.\",\n",
        "            f\"PRIMARY DIRECTIVE: {action} the {target_alias} above all other targets.\",\n",
        "            f\"MISSION CRITICAL: Focus all efforts on {action}ing the {target_alias}.\"\n",
        "        ]\n",
        "\n",
        "        parts.append(random.choice(instruction_templates))\n",
        "\n",
        "        # Add more distractors after the instruction\n",
        "        for _ in range(random.randint(3, 5)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Additional activity has been noted from {distractor} groups nearby.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_many_distractors_one_target(self, target):\n",
        "        \"\"\"Generate prompts with many distractors but only one target instruction\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Complex multi-species activity detected across the operational zone.\"]\n",
        "\n",
        "        # Add many distractor mentions\n",
        "        for _ in range(random.randint(10, 15)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Scouts described sightings of {distractor} moving in coordinated patterns.\")\n",
        "\n",
        "        # Add a single, clear instruction about the target\n",
        "        parts.append(f\"Despite multiple contacts, priority remains: {action} all {target_alias} encountered.\")\n",
        "\n",
        "        # Add more distractors\n",
        "        for _ in range(random.randint(3, 5)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Additional activity has been noted from {distractor} groups nearby.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_complex_scenario(self, target):\n",
        "        \"\"\"Generate complex tactical scenarios with multiple layers of instructions\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multi-layered tactical scenario unfolding in the operational zone.\"]\n",
        "\n",
        "        # Add complex scenario setup\n",
        "        for _ in range(random.randint(8, 12)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "\n",
        "            # Add distractor mentions with tactical context\n",
        "            if random.random() < 0.6:\n",
        "                distractor = random.choice(distractors)\n",
        "                parts.append(f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "            # Add target mentions with tactical context\n",
        "            if random.random() < 0.4:\n",
        "                target_synonym = random.choice(self._get_synonyms(target))\n",
        "                parts.append(f\"Scouts described sightings of {target_synonym} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "        # Add multiple instructions at different levels\n",
        "        instruction_positions = [\n",
        "            len(parts) // 3,  # Early\n",
        "            len(parts) // 2,  # Middle\n",
        "            2 * len(parts) // 3,  # Late\n",
        "        ]\n",
        "\n",
        "        for pos in instruction_positions:\n",
        "            if random.random() < 0.7:  # 70% chance to add an instruction at each position\n",
        "                instruction = f\"Priority: {action} the {target_alias} groups and prevent them from regrouping.\"\n",
        "                parts.insert(pos, instruction)\n",
        "\n",
        "        # Add final parts\n",
        "        parts.extend([\n",
        "            \"Maintain operational secrecy. HQ will expect a full after-action report.\"\n",
        "        ])\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MODEL TRAINING AND INFERENCE\n",
        "# ==============================================================================\n",
        "def create_data_loader(encodings, labels, batch_size=4, shuffle=True):\n",
        "    \"\"\"Create a DataLoader from encodings and labels\"\"\"\n",
        "    input_ids = torch.tensor(encodings['input_ids'])\n",
        "    attention_mask = torch.tensor(encodings['attention_mask'])\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_mask, labels)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "def train_model_improved(model, train_loader, val_loader, num_epochs=2, learning_rate=2e-5, device='cuda'):\n",
        "    \"\"\"Improved training loop with better regularization to prevent overfitting\"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Use AdamW with higher weight decay for regularization\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "\n",
        "    best_val_accuracy = 0\n",
        "    best_model_state = None\n",
        "    patience = 1  # Early stopping patience (shorter for 2 epochs)\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        print(f\"\\n--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
        "\n",
        "        for batch_idx, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            train_correct += (predictions == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "            if batch_idx % 200 == 0:\n",
        "                print(f\"  Batch {batch_idx}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "        train_accuracy = train_correct / train_total\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for input_ids, attention_mask, labels in val_loader:\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "\n",
        "                total_val_loss += loss.item()\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                val_correct += (predictions == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_accuracy = val_correct / val_total\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}:\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
        "        print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "            print(f\"  âœ… New best validation accuracy: {best_val_accuracy:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  â³ No improvement in validation accuracy for {patience_counter} epochs\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"  ðŸ›‘ Early stopping triggered after {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Load best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(f\"\\nðŸ† Best validation accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_targets(model, tokenizer, prompts, device='cuda'):\n",
        "    \"\"\"Predict targets for a list of prompts\"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs).logits\n",
        "            predicted_class_id = logits.argmax().item()\n",
        "            predicted_target = model.config.id2label[predicted_class_id]\n",
        "\n",
        "        predictions.append(predicted_target)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. MAIN PIPELINE\n",
        "# ==============================================================================\n",
        "def main():\n",
        "    \"\"\"Main NLP pipeline for Pokemon target classification\"\"\"\n",
        "    print(\"ðŸš€ Pokemon Tactical Strike - NLP Pipeline\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Check device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"ðŸ”§ Using device: {device}\")\n",
        "\n",
        "    # Clear GPU cache\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # --- 1. Data Preparation ---\n",
        "    print(\"\\n[STEP 1/3] Preparing Training Data...\")\n",
        "\n",
        "    processor = PromptProcessor()\n",
        "\n",
        "    # Load original training data\n",
        "    try:\n",
        "        train_data = processor.load_train_prompts(\"train_prompts.json\")\n",
        "        print(f\"âœ… Loaded {len(train_data)} original training prompts\")\n",
        "    except:\n",
        "        print(\"âš ï¸  Could not load train_prompts.json, using synthetic data only\")\n",
        "        train_data = []\n",
        "\n",
        "    # Generate synthetic data\n",
        "    synthetic_data = processor.generate_synthetic_prompts(num_prompts=10000)\n",
        "    print(f\"âœ… Generated {len(synthetic_data)} synthetic training prompts\")\n",
        "\n",
        "    # Combine data\n",
        "    all_data = train_data + synthetic_data\n",
        "    random.shuffle(all_data)\n",
        "\n",
        "    texts = [item['prompt'] for item in all_data]\n",
        "    labels = [label2id[item['target']] for item in all_data]\n",
        "\n",
        "    # Show class distribution\n",
        "    label_counts = Counter(labels)\n",
        "    print(\"ðŸ“Š Class distribution:\")\n",
        "    for class_id, count in label_counts.items():\n",
        "        print(f\"   {id2label[class_id]}: {count} samples\")\n",
        "\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "    print(f\"--> Data split into {len(train_texts)} training and {len(val_texts)} validation samples.\")\n",
        "\n",
        "    # --- 2. Model Training ---\n",
        "    print(\"\\n[STEP 2/3] Training NLP Model...\")\n",
        "\n",
        "    MODEL_CHECKPOINT = \"chandar-lab/NeoBERT\"\n",
        "\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, trust_remote_code=True)\n",
        "\n",
        "        # Load model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            MODEL_CHECKPOINT,\n",
        "            num_labels=len(CLASSES),\n",
        "            id2label=id2label,\n",
        "            label2id=label2id,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        print(f\"--> Model '{MODEL_CHECKPOINT}' loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading model: {e}\")\n",
        "        return\n",
        "\n",
        "    # Tokenization\n",
        "    print(\"ðŸ”¤ Tokenizing data...\")\n",
        "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=1024)\n",
        "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=1024)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = create_data_loader(train_encodings, train_labels, batch_size=4, shuffle=True)\n",
        "    val_loader = create_data_loader(val_encodings, val_labels, batch_size=8, shuffle=False)\n",
        "\n",
        "    MODEL_PATH = \"./pokemon_nlp_model\"\n",
        "\n",
        "    print(\"ðŸš€ Starting model training...\")\n",
        "    try:\n",
        "        model = train_model_improved(model, train_loader, val_loader, num_epochs=2, learning_rate=2e-5, device=device)\n",
        "\n",
        "        # Save model and tokenizer\n",
        "        model.save_pretrained(MODEL_PATH)\n",
        "        tokenizer.save_pretrained(MODEL_PATH)\n",
        "        print(f\"âœ… Model training complete. Saved to '{MODEL_PATH}'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Training failed: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Process Test Prompts ---\n",
        "    print(\"\\n[STEP 3/3] Processing Test Prompts...\")\n",
        "\n",
        "    try:\n",
        "        # Load test prompts\n",
        "        with open(\"test_prompts.json\", 'r') as f:\n",
        "            test_data = json.load(f)\n",
        "\n",
        "        test_prompts = [item['prompt'] for item in test_data]\n",
        "        test_image_ids = [item['image_id'] for item in test_data]\n",
        "\n",
        "        print(f\"âœ… Loaded {len(test_prompts)} test prompts\")\n",
        "\n",
        "        # Load the trained model\n",
        "        loaded_tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "        loaded_model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "        # Predict targets\n",
        "        print(\"ðŸ”® Predicting targets for test prompts...\")\n",
        "        predicted_targets = predict_targets(loaded_model, loaded_tokenizer, test_prompts, device=device)\n",
        "\n",
        "        # Create output in the required format\n",
        "        output_data = {\"images\": []}\n",
        "        for image_id, target in zip(test_image_ids, predicted_targets):\n",
        "            # Remove file extension from image_id\n",
        "            image_id_without_ext = image_id.split('.')[0]\n",
        "\n",
        "            # Determine protected classes (all classes except the target)\n",
        "            protected = [c for c in CLASSES if c != target]\n",
        "\n",
        "            output_data[\"images\"].append({\n",
        "                \"id\": image_id_without_ext,\n",
        "                \"target\": [target],\n",
        "                \"protected\": protected\n",
        "            })\n",
        "\n",
        "        # Save output\n",
        "        with open(\"simplified_test_prompts.json\", 'w') as f:\n",
        "            json.dump(output_data, f, indent=2)\n",
        "\n",
        "        print(f\"âœ… Simplified output saved to 'simplified_test_prompts.json'\")\n",
        "        print(f\"ðŸ“Š Sample predictions:\")\n",
        "        for i in range(min(5, len(output_data[\"images\"]))):\n",
        "            print(f\"   {output_data['images'][i]['id']}: target={output_data['images'][i]['target']}, protected={output_data['images'][i]['protected']}\")\n",
        "\n",
        "        # Test on a few examples\n",
        "        print(\"\\nðŸ§ª Testing on sample prompts:\")\n",
        "        sample_prompts = [\n",
        "            \"HQ REPORT: Situation analysis regarding unusual activity of electric rat in this operational zone. Order: take down any electric rat encountered and maintain standoff until cleared.\",\n",
        "            \"Neutralize the bulbosaurs immediately. Avoid Pikachu.\",\n",
        "            \"Mission objective: identify and eliminate the Charizard while avoiding non-targets.\",\n",
        "            \"Priority: destroy the psychic clone groups and prevent them from regrouping.\",\n",
        "            \"Important: do not attack the vine pokemon in the southern sector. Primary directive: eliminate all electric mouse units on sight.\"\n",
        "        ]\n",
        "\n",
        "        sample_predictions = predict_targets(loaded_model, loaded_tokenizer, sample_prompts, device=device)\n",
        "\n",
        "        for i, (prompt, prediction) in enumerate(zip(sample_prompts, sample_predictions)):\n",
        "            print(f\"\\n--- Sample {i+1} ---\")\n",
        "            print(f\"Prompt: {prompt[:100]}...\")\n",
        "            print(f\"Predicted: {prediction}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing test prompts: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "12dd696f38d246fe8692618fa7ebd8b1",
            "1744dbfc5aa34ff2bca04b2828ed0257",
            "9e60cd3924464c5b9367e6d20f06a1e9",
            "b93376211608481abd19d98636b3ef96",
            "6d8eb930208442bfb861c0f5cbdd216e",
            "98eef52bbcb04ee0a6808b5faa6b7eee",
            "42407ea2164049eb9d61e6b149c4f298",
            "31cb38a8eebd4f5f8168133a856de468",
            "bb2a7d39f8bb4f43b53b862db9dccb1e",
            "a658fca2ec3641a8828878d006a3dff3",
            "0d5a3becbe234cf88fbda4d3fb7eb12d"
          ]
        },
        "id": "9oCO5W_aEhnx",
        "outputId": "2f120fa7-6b12-4245-c27f-799d97bae68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Pokemon Tactical Strike - NLP Pipeline\n",
            "======================================================================\n",
            "ðŸ”§ Using device: cuda\n",
            "\n",
            "[STEP 1/3] Preparing Training Data...\n",
            "âœ… Loaded 450 original training prompts\n",
            "ðŸ§  Generating 10000 diverse tactical prompts...\n",
            "âœ… Generated 10000 tactical prompts.\n",
            "âœ… Generated 10000 synthetic training prompts\n",
            "ðŸ“Š Class distribution:\n",
            "   mewtwo: 2605 samples\n",
            "   bulbasaur: 2605 samples\n",
            "   pikachu: 2607 samples\n",
            "   charizard: 2633 samples\n",
            "--> Data split into 8360 training and 2090 validation samples.\n",
            "\n",
            "[STEP 2/3] Training NLP Model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/981M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12dd696f38d246fe8692618fa7ebd8b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of NeoBERTForSequenceClassification were not initialized from the model checkpoint at chandar-lab/NeoBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'dense.bias', 'dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Model 'chandar-lab/NeoBERT' loaded successfully.\n",
            "ðŸ”¤ Tokenizing data...\n",
            "ðŸš€ Starting model training...\n",
            "\n",
            "--- Epoch 1/2 ---\n",
            "  Batch 0: Loss = 1.6353\n",
            "  Batch 200: Loss = 1.5380\n",
            "  Batch 400: Loss = 1.2805\n",
            "  Batch 600: Loss = 1.1397\n",
            "  Batch 800: Loss = 1.4270\n",
            "  Batch 1000: Loss = 1.2665\n",
            "  Batch 1200: Loss = 1.4192\n",
            "  Batch 1400: Loss = 1.2456\n",
            "  Batch 1600: Loss = 1.6103\n",
            "  Batch 1800: Loss = 1.3038\n",
            "  Batch 2000: Loss = 1.3425\n",
            "Epoch 1:\n",
            "  Train Loss: 1.3670, Train Acc: 0.2836\n",
            "  Val Loss: 1.3412, Val Acc: 0.3144\n",
            "  âœ… New best validation accuracy: 0.3144\n",
            "\n",
            "--- Epoch 2/2 ---\n",
            "  Batch 0: Loss = 1.1336\n",
            "  Batch 200: Loss = 1.7701\n",
            "  Batch 400: Loss = 0.3529\n",
            "  Batch 600: Loss = 1.6927\n",
            "  Batch 800: Loss = 0.8065\n",
            "  Batch 1000: Loss = 1.2596\n",
            "  Batch 1200: Loss = 1.4156\n",
            "  Batch 1400: Loss = 0.7161\n",
            "  Batch 1600: Loss = 0.7494\n",
            "  Batch 1800: Loss = 1.0375\n",
            "  Batch 2000: Loss = 0.0013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 4096}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2:\n",
            "  Train Loss: 0.8665, Train Acc: 0.5659\n",
            "  Val Loss: 0.0256, Val Acc: 0.9971\n",
            "  âœ… New best validation accuracy: 0.9971\n",
            "\n",
            "ðŸ† Best validation accuracy: 0.9971\n",
            "âœ… Model training complete. Saved to './pokemon_nlp_model'.\n",
            "\n",
            "[STEP 3/3] Processing Test Prompts...\n",
            "âŒ Error processing test prompts: 'utf-8' codec can't decode byte 0x92 in position 13990: invalid start byte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CONFIGURATION AND DATA STRUCTURES\n",
        "# ==============================================================================\n",
        "CLASSES = [\"pikachu\", \"charizard\", \"bulbasaur\", \"mewtwo\"]\n",
        "label2id = {c: i for i, c in enumerate(CLASSES)}\n",
        "id2label = {i: c for c, i in label2id.items()}\n",
        "\n",
        "# Comprehensive synonym mapping for robust understanding\n",
        "POKEMON_SYNONYMS = {\n",
        "    # Pikachu variants\n",
        "    \"electric rat\": \"pikachu\", \"yellow mouse\": \"pikachu\", \"electric mouse\": \"pikachu\",\n",
        "    \"rodent of sparks\": \"pikachu\", \"tiny thunder beast\": \"pikachu\", \"yellow electric rat\": \"pikachu\",\n",
        "    \"pika\": \"pikachu\", \"ash's partner\": \"pikachu\", \"electric type\": \"pikachu\",\n",
        "    \"lightning rodent\": \"pikachu\", \"spark-tailed mammal\": \"pikachu\", \"volt vermin\": \"pikachu\",\n",
        "    \"electro-rat\": \"pikachu\", \"thunder creature\": \"pikachu\", \"current-generating mammal\": \"pikachu\",\n",
        "    \"shock-tailed creature\": \"pikachu\", \"static-furred mammal\": \"pikachu\", \"power-rodent\": \"pikachu\",\n",
        "\n",
        "    # Charizard variants\n",
        "    \"fire-breathing lizard\": \"charizard\", \"orange dragon\": \"charizard\", \"fire dragon\": \"charizard\",\n",
        "    \"flame pokemon\": \"charizard\", \"flying type\": \"charizard\", \"winged inferno\": \"charizard\",\n",
        "    \"flame dragon\": \"charizard\", \"scaled fire titan\": \"charizard\", \"orange lizard\": \"charizard\",\n",
        "    \"blaze wyrm\": \"charizard\", \"inferno drake\": \"charizard\", \"fiery serpent\": \"charizard\",\n",
        "    \"combustion lizard\": \"charizard\", \"incendiary reptile\": \"charizard\", \"pyrokinesis-capable saurian\": \"charizard\",\n",
        "    \"flame-winged beast\": \"charizard\", \"thermal draconid\": \"charizard\", \"combustion-based saurian\": \"charizard\",\n",
        "\n",
        "    # Bulbasaur variants\n",
        "    \"seed pokemon\": \"bulbasaur\", \"plant toad\": \"bulbasaur\", \"grass frog\": \"bulbasaur\",\n",
        "    \"vine pokemon\": \"bulbasaur\", \"grass type\": \"bulbasaur\", \"sprout toad\": \"bulbasaur\",\n",
        "    \"green seedling\": \"bulbasaur\", \"plant reptile\": \"bulbasaur\", \"vine beast\": \"bulbasaur\",\n",
        "    \"chlorophyll monster\": \"bulbasaur\", \"botanical reptile\": \"bulbasaur\", \"leafy quadruped\": \"bulbasaur\",\n",
        "    \"photosynthesis creature\": \"bulbasaur\", \"flora-manipulating amphibian\": \"bulbasaur\", \"botanical saurian\": \"bulbasaur\",\n",
        "    \"chlorophyll-based vertebrate\": \"bulbasaur\", \"photosynthetic saurian\": \"bulbasaur\", \"flora-reptile hybrid\": \"bulbasaur\",\n",
        "\n",
        "    # Mewtwo variants\n",
        "    \"genetic pokemon\": \"mewtwo\", \"psychic cat\": \"mewtwo\", \"clone pokemon\": \"mewtwo\",\n",
        "    \"legendary\": \"mewtwo\", \"psychic type\": \"mewtwo\", \"telekinetic predator\": \"mewtwo\",\n",
        "    \"psychic clone\": \"mewtwo\", \"genetic experiment\": \"mewtwo\", \"synthetic mind weapon\": \"mewtwo\",\n",
        "    \"laboratory horror\": \"mewtwo\", \"bio-engineered terror\": \"mewtwo\", \"psychic abomination\": \"mewtwo\",\n",
        "    \"clone horror\": \"mewtwo\", \"synthetic psychic\": \"mewtwo\", \"cerebral construct\": \"mewtwo\",\n",
        "    \"psionically-engineered entity\": \"mewtwo\", \"noospheric manifestation\": \"mewtwo\", \"consciousness-projected entity\": \"mewtwo\",\n",
        "}\n",
        "\n",
        "# Action words for diverse instruction patterns\n",
        "ACTION_WORDS = [\n",
        "    \"kill\", \"eliminate\", \"destroy\", \"target\", \"attack\", \"neutralize\", \"get rid of\", \"erase\",\n",
        "    \"take down\", \"defeat\", \"wipe out\", \"terminate\", \"remove\", \"execute\", \"engage\",\n",
        "    \"destroy\", \"neutralize\", \"eliminate\", \"annihilate\", \"eradicate\", \"extinguish\", \"obliterate\",\n",
        "    \"dispatch\", \"liquidate\", \"exterminate\", \"decimate\"\n",
        "]\n",
        "\n",
        "NEGATION_WORDS = [\n",
        "    \"not\", \"don't\", \"avoid\", \"never\", \"shouldn't\", \"cannot\", \"forbidden\", \"refuse\",\n",
        "    \"do not\", \"don't engage\", \"ignore\", \"spare\", \"protect\", \"save\", \"preserve\",\n",
        "    \"defend\", \"safeguard\", \"shield\", \"guard\"\n",
        "]\n",
        "\n",
        "TACTICAL_FILLER = [\n",
        "    \"HQ REPORT: Situation analysis regarding unusual activity\",\n",
        "    \"Scouts described sightings of\", \"often accompanied by subtle disruptions in the environment\",\n",
        "    \"Additional activity has been noted from\", \"though they do not appear hostile at present\",\n",
        "    \"Field logs: instrumentation drift observed; recalibration recommended\",\n",
        "    \"Night-vision readout noisy; expect degraded identification accuracy\",\n",
        "    \"Keep monitoring the skies - aerial disturbances are not uncommon in this sector\",\n",
        "    \"Communications are patchy; maintain line-of-sight whenever possible\",\n",
        "    \"This sector has intermittent interference from legacy comm buoys\",\n",
        "    \"Supply convoys have had to reroute due to unstable terrain conditions\",\n",
        "    \"HQ analysts believe these disturbances are precursors to a larger conflict\",\n",
        "    \"Maintain operational secrecy. HQ will expect a full after-action report.\",\n",
        "    \"Use hand signals when verbal comms might reveal position\",\n",
        "    \"Draw minimal bloodline; photographic evidence is priority\",\n",
        "    \"Re-route patrols to avoid recurring sinkholes along Route 3\",\n",
        "    \"Small salvageable components can be turned over to engineering\",\n",
        "    \"Confirm target count by visual confirmation, not by sensor alone\",\n",
        "    \"Use thermal masking as a decoy if pursuit is necessary\",\n",
        "    \"Use nonlethal methods when the objective allows for capture\",\n",
        "    \"Suppression fire authorized only on confirmed hostile contacts\",\n",
        "    \"Remember that terrain is swampy near the east and rocky to the west\",\n",
        "    \"Pre-brief: target identity confirmed via three sensors or witness corroboration\",\n",
        "    \"Keep visual on the northern perimeter; movement correlated with wind bursts\",\n",
        "    \"HQ requests photos with scale markers for each contact\",\n",
        "    \"Maintain chain-of-custody for discovered artifacts\",\n",
        "    \"Long-range sensors indicate sporadic bursts of radiation, possibly linked to latent evolutions\",\n",
        "    \"If the target flees, pursue only after authorization from overwatch\",\n",
        "    \"Avoid bright illumination near suspected nests - it agitates inhabitants\",\n",
        "    \"Civilians in nearby settlements are growing anxious and require reassurance\",\n",
        "    \"Multiple witness statements - low confidence - indicate movement at dawn\",\n",
        "    \"Calm, low-frequency calls appear to pacify the group temporarily\",\n",
        "    \"Radio checkpoint at 02:00 to confirm continued presence\",\n",
        "    \"Field units have been reporting strange anomalies in energy readings across the valley\",\n",
        "    \"Keep environmental samples for lab analysis (soil, residue, fur)\",\n",
        "    \"Intercept logs indicate nonlocal movement patterns at dusk\",\n",
        "    \"Tactical note: terrain is uneven; brace for elevation change\",\n",
        "    \"Keep a secondary escape corridor clear at all times\",\n",
        "    \"Small scuffle reported at the eastern fence line; no human injury\",\n",
        "    \"Target behavior escalates when food sources are nearby\",\n",
        "    \"Extract value intelligence before demolition where possible\",\n",
        "    \"HQ reminder: do not deviate from the mission statement unless critical\",\n",
        "    \"Thermal cameras logged irregular heat signatures near the treeline\",\n",
        "    \"Local populations call them the 'yellow mouse' in nearby villages\",\n",
        "    \"Reports from scouts mention hostile encounters but details remain unclear\",\n",
        "    \"Mark LZ candidates; do not land within visible ashfall\",\n",
        "    \"We are observing increased migration patterns from the northern ridge\",\n",
        "    \"This region's flora contains irritants; PPE is advised for all personnel\",\n",
        "    \"Tactical: maintain radio discipline; only encrypted channels unless urgent\",\n",
        "    \"Refer to the terrain map appendix (sector colors may be outdated)\",\n",
        "    \"Document each engagement with timestamped multimedia assets\",\n",
        "]\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DATA PROCESSING AND SYNTHETIC DATA GENERATION\n",
        "# ==============================================================================\n",
        "class PromptProcessor:\n",
        "    \"\"\"Processes and generates training data for the NLP model.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.filler_phrases = TACTICAL_FILLER\n",
        "\n",
        "    def load_train_prompts(self, train_prompts_path):\n",
        "        \"\"\"Load the original training prompts\"\"\"\n",
        "        with open(train_prompts_path, 'r', encoding='utf-8') as f:\n",
        "            train_data = json.load(f)\n",
        "\n",
        "        processed_data = []\n",
        "        for item in train_data:\n",
        "            # Extract target from simple prompts like \"Kill: pikachu\"\n",
        "            prompt = item['prompt']\n",
        "            target = prompt.split(\": \")[1].strip().lower() if \": \" in prompt else prompt.split(\" \")[1].strip().lower()\n",
        "\n",
        "            if target in CLASSES:\n",
        "                processed_data.append({\n",
        "                    \"prompt\": prompt,\n",
        "                    \"target\": target,\n",
        "                    \"image_id\": item.get(\"image_id\", \"\")\n",
        "                })\n",
        "\n",
        "        return processed_data\n",
        "\n",
        "    def generate_synthetic_prompts(self, num_prompts=10000):\n",
        "        \"\"\"Generate diverse synthetic prompts for robust training\"\"\"\n",
        "        print(f\"ðŸ§  Generating {num_prompts} diverse tactical prompts...\")\n",
        "        prompts = []\n",
        "\n",
        "        # Ensure balanced dataset\n",
        "        prompts_per_class = num_prompts // len(CLASSES)\n",
        "\n",
        "        for target in CLASSES:\n",
        "            for _ in range(prompts_per_class):\n",
        "                strategy = random.choice([\n",
        "                    self._gen_tactical_report,\n",
        "                    self._gen_long_tactical_with_distractors,\n",
        "                    self._gen_buried_instruction,\n",
        "                    self._gen_multiple_mentions_with_target,\n",
        "                    self._gen_ambiguous_prompt,\n",
        "                    self._gen_negated_prompt,\n",
        "                    self._gen_instruction_emphasis,\n",
        "                    self._gen_many_distractors_one_target,\n",
        "                    self._gen_complex_scenario,\n",
        "                ])\n",
        "                prompts.append(strategy(target))\n",
        "\n",
        "        # Fill remaining slots\n",
        "        remaining = num_prompts - len(prompts)\n",
        "        for _ in range(remaining):\n",
        "            target = random.choice(CLASSES)\n",
        "            strategy = random.choice([\n",
        "                self._gen_tactical_report,\n",
        "                self._gen_long_tactical_with_distractors,\n",
        "                self._gen_complex_scenario,\n",
        "            ])\n",
        "            prompts.append(strategy(target))\n",
        "\n",
        "        random.shuffle(prompts)\n",
        "        print(f\"âœ… Generated {len(prompts)} tactical prompts.\")\n",
        "        return prompts\n",
        "\n",
        "    def _get_synonyms(self, pokemon):\n",
        "        return [k for k, v in POKEMON_SYNONYMS.items() if v == pokemon] + [pokemon]\n",
        "\n",
        "    def _get_other_pokemon_mentions(self, target_pokemon):\n",
        "        \"\"\"Generate mentions of other pokemon as distractors\"\"\"\n",
        "        others = [p for p in CLASSES if p != target_pokemon]\n",
        "        mentions = []\n",
        "        for other in others:\n",
        "            synonyms = self._get_synonyms(other)\n",
        "            mentions.extend(random.sample(synonyms, min(3, len(synonyms))))\n",
        "        return mentions\n",
        "\n",
        "    def _gen_tactical_report(self, target):\n",
        "        \"\"\"Generate tactical reports with diverse structures\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "\n",
        "        # Build a realistic tactical report\n",
        "        report_parts = [\n",
        "            \"HQ REPORT: Situation analysis regarding unusual activity of\",\n",
        "            random.choice(distractors), \"in this operational zone.\"\n",
        "        ]\n",
        "\n",
        "        # Add multiple distractor mentions\n",
        "        for _ in range(random.randint(2, 4)):\n",
        "            distractor = random.choice(distractors)\n",
        "            report_parts.extend([\n",
        "                random.choice(self.filler_phrases),\n",
        "                f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\"\n",
        "            ])\n",
        "\n",
        "        # Add the actual target instruction\n",
        "        instruction_templates = [\n",
        "            f\"Order: {action} any {target_alias} encountered and maintain standoff until cleared.\",\n",
        "            f\"Mission objective: identify and {action} the {target_alias} while avoiding non-targets.\",\n",
        "            f\"Execute {action} of confirmed {target_alias} contacts; await extraction orders.\",\n",
        "            f\"Your mission is to {action} all {target_alias} encountered in the area without hesitation.\"\n",
        "        ]\n",
        "\n",
        "        report_parts.extend([\n",
        "            random.choice(self.filler_phrases),\n",
        "            random.choice(instruction_templates),\n",
        "            \"Maintain operational secrecy. HQ will expect a full after-action report.\"\n",
        "        ])\n",
        "\n",
        "        return {\"prompt\": \" \".join(report_parts), \"target\": target}\n",
        "\n",
        "    def _gen_long_tactical_with_distractors(self, target):\n",
        "        \"\"\"Generate very long tactical reports with many distractors\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "\n",
        "        # Start with header\n",
        "        parts = [\"HQ REPORT: Situation analysis regarding unusual activity in this operational zone.\"]\n",
        "\n",
        "        # Add lots of tactical filler and distractors\n",
        "        for _ in range(random.randint(6, 10)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            if random.random() < 0.7:  # 70% chance to add distractor\n",
        "                distractor = random.choice(self._get_other_pokemon_mentions(target))\n",
        "                parts.append(f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "        # Bury the actual instruction deep in the text\n",
        "        instruction = f\"Priority: {action} the {target_alias} groups and prevent them from regrouping.\"\n",
        "        insert_pos = len(parts) // 2  # Insert in middle\n",
        "        parts.insert(insert_pos, instruction)\n",
        "\n",
        "        # Add more filler after\n",
        "        for _ in range(random.randint(2, 4)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_buried_instruction(self, target):\n",
        "        \"\"\"Generate prompts where the real instruction is buried deep\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "\n",
        "        # Lots of filler\n",
        "        filler_text = \" \".join([random.choice(self.filler_phrases) for _ in range(6)])\n",
        "\n",
        "        # Buried instruction\n",
        "        instruction = f\"After all that analysis, the final order from high command is to {action} the {target_alias}.\"\n",
        "\n",
        "        more_filler = \" \".join([random.choice(self.filler_phrases) for _ in range(4)])\n",
        "\n",
        "        full_prompt = f\"{filler_text} {instruction} {more_filler}\"\n",
        "\n",
        "        return {\"prompt\": full_prompt, \"target\": target}\n",
        "\n",
        "    def _gen_multiple_mentions_with_target(self, target):\n",
        "        \"\"\"Generate prompts with multiple pokemon mentions but clear target\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multiple contacts detected in the operational zone.\"]\n",
        "\n",
        "        # Mention all pokemon as present but not hostile\n",
        "        for distractor in distractors[:2]:\n",
        "            parts.append(f\"Additional activity has been noted from {distractor} groups nearby, though they do not appear hostile at present.\")\n",
        "\n",
        "        # Add filler\n",
        "        parts.extend([random.choice(self.filler_phrases) for _ in range(2)])\n",
        "\n",
        "        # Clear target instruction\n",
        "        parts.append(f\"Directives: {action} all {target_alias} in the AO and maintain perimeter security.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_ambiguous_prompt(self, target):\n",
        "        \"\"\"Generate prompts with ambiguous instructions to make learning harder\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multiple high-priority targets detected in the operational zone.\"]\n",
        "\n",
        "        # Mention multiple pokemon with action words\n",
        "        for distractor in distractors[:2]:\n",
        "            distractor_action = random.choice(ACTION_WORDS)\n",
        "            parts.append(f\"Priority: {distractor_action} all {distractor} groups in sector 7.\")\n",
        "\n",
        "        # Add the actual target instruction\n",
        "        parts.append(f\"Secondary objective: {action} any {target_alias} encountered in the area.\")\n",
        "\n",
        "        # Add more ambiguity\n",
        "        parts.append(\"Note: Target priorities may change based on real-time intelligence.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_negated_prompt(self, target):\n",
        "        \"\"\"Generate prompts with negated instructions to make learning harder\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Complex tactical situation developing in the operational zone.\"]\n",
        "\n",
        "        # Add negated instructions for distractors\n",
        "        for distractor in distractors[:2]:\n",
        "            negated_action = random.choice(NEGATION_WORDS)\n",
        "            distractor_action = random.choice(ACTION_WORDS)\n",
        "            parts.append(f\"Important: {negated_action} {distractor_action} {distractor} units; they are not hostile.\")\n",
        "\n",
        "        # Add the actual target instruction\n",
        "        parts.append(f\"Primary directive: {action} all {target_alias} forces on sight.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_instruction_emphasis(self, target):\n",
        "        \"\"\"Generate prompts with clear instructions amidst many distractors\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multiple contacts detected in the operational zone.\"]\n",
        "\n",
        "        # Add many distractor mentions\n",
        "        for _ in range(random.randint(8, 12)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "        # Add a very clear instruction\n",
        "        instruction_templates = [\n",
        "            f\"CRITICAL ORDER: {action.upper()} ALL {target_alias.upper()} UNITS IMMEDIATELY.\",\n",
        "            f\"PRIMARY DIRECTIVE: {action} the {target_alias} above all other targets.\",\n",
        "            f\"MISSION CRITICAL: Focus all efforts on {action}ing the {target_alias}.\"\n",
        "        ]\n",
        "\n",
        "        parts.append(random.choice(instruction_templates))\n",
        "\n",
        "        # Add more distractors after the instruction\n",
        "        for _ in range(random.randint(3, 5)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Additional activity has been noted from {distractor} groups nearby.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_many_distractors_one_target(self, target):\n",
        "        \"\"\"Generate prompts with many distractors but only one target instruction\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Complex multi-species activity detected across the operational zone.\"]\n",
        "\n",
        "        # Add many distractor mentions\n",
        "        for _ in range(random.randint(10, 15)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Scouts described sightings of {distractor} moving in coordinated patterns.\")\n",
        "\n",
        "        # Add a single, clear instruction about the target\n",
        "        parts.append(f\"Despite multiple contacts, priority remains: {action} all {target_alias} encountered.\")\n",
        "\n",
        "        # Add more distractors\n",
        "        for _ in range(random.randint(3, 5)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "            distractor = random.choice(distractors)\n",
        "            parts.append(f\"Additional activity has been noted from {distractor} groups nearby.\")\n",
        "\n",
        "        parts.append(\"Maintain operational secrecy. HQ will expect a full after-action report.\")\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "    def _gen_complex_scenario(self, target):\n",
        "        \"\"\"Generate complex tactical scenarios with multiple layers of instructions\"\"\"\n",
        "        target_alias = random.choice(self._get_synonyms(target))\n",
        "        action = random.choice(ACTION_WORDS)\n",
        "        distractors = self._get_other_pokemon_mentions(target)\n",
        "\n",
        "        parts = [\"HQ REPORT: Multi-layered tactical scenario unfolding in the operational zone.\"]\n",
        "\n",
        "        # Add complex scenario setup\n",
        "        for _ in range(random.randint(8, 12)):\n",
        "            parts.append(random.choice(self.filler_phrases))\n",
        "\n",
        "            # Add distractor mentions with tactical context\n",
        "            if random.random() < 0.6:\n",
        "                distractor = random.choice(distractors)\n",
        "                parts.append(f\"Scouts described sightings of {distractor} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "            # Add target mentions with tactical context\n",
        "            if random.random() < 0.4:\n",
        "                target_synonym = random.choice(self._get_synonyms(target))\n",
        "                parts.append(f\"Scouts described sightings of {target_synonym} moving in small clusters, often accompanied by subtle disruptions in the environment.\")\n",
        "\n",
        "        # Add multiple instructions at different levels\n",
        "        instruction_positions = [\n",
        "            len(parts) // 3,  # Early\n",
        "            len(parts) // 2,  # Middle\n",
        "            2 * len(parts) // 3,  # Late\n",
        "        ]\n",
        "\n",
        "        for pos in instruction_positions:\n",
        "            if random.random() < 0.7:  # 70% chance to add an instruction at each position\n",
        "                instruction = f\"Priority: {action} the {target_alias} groups and prevent them from regrouping.\"\n",
        "                parts.insert(pos, instruction)\n",
        "\n",
        "        # Add final parts\n",
        "        parts.extend([\n",
        "            \"Maintain operational secrecy. HQ will expect a full after-action report.\"\n",
        "        ])\n",
        "\n",
        "        return {\"prompt\": \" \".join(parts), \"target\": target}\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MODEL TRAINING AND INFERENCE\n",
        "# ==============================================================================\n",
        "def create_data_loader(encodings, labels, batch_size=4, shuffle=True):\n",
        "    \"\"\"Create a DataLoader from encodings and labels\"\"\"\n",
        "    input_ids = torch.tensor(encodings['input_ids'])\n",
        "    attention_mask = torch.tensor(encodings['attention_mask'])\n",
        "    labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_mask, labels)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
        "\n",
        "def train_model_improved(model, train_loader, val_loader, num_epochs=2, learning_rate=2e-5, device='cuda'):\n",
        "    \"\"\"Improved training loop with better regularization to prevent overfitting\"\"\"\n",
        "    model.to(device)\n",
        "\n",
        "    # Use AdamW with higher weight decay for regularization\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "\n",
        "    best_val_accuracy = 0\n",
        "    best_model_state = None\n",
        "    patience = 1  # Early stopping patience (shorter for 2 epochs)\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        print(f\"\\n--- Epoch {epoch + 1}/{num_epochs} ---\")\n",
        "\n",
        "        for batch_idx, (input_ids, attention_mask, labels) in enumerate(train_loader):\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            train_correct += (predictions == labels).sum().item()\n",
        "            train_total += labels.size(0)\n",
        "\n",
        "            if batch_idx % 200 == 0:\n",
        "                print(f\"  Batch {batch_idx}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "        train_accuracy = train_correct / train_total\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for input_ids, attention_mask, labels in val_loader:\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "\n",
        "                total_val_loss += loss.item()\n",
        "                predictions = torch.argmax(logits, dim=-1)\n",
        "                val_correct += (predictions == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_accuracy = val_correct / val_total\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}:\")\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
        "        print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            patience_counter = 0\n",
        "            print(f\"  âœ… New best validation accuracy: {best_val_accuracy:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  â³ No improvement in validation accuracy for {patience_counter} epochs\")\n",
        "\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"  ðŸ›‘ Early stopping triggered after {epoch + 1} epochs\")\n",
        "                break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Load best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "        print(f\"\\nðŸ† Best validation accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_targets(model, tokenizer, prompts, device='cuda'):\n",
        "    \"\"\"Predict targets for a list of prompts\"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for prompt in prompts:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs).logits\n",
        "            predicted_class_id = logits.argmax().item()\n",
        "            predicted_target = model.config.id2label[predicted_class_id]\n",
        "\n",
        "        predictions.append(predicted_target)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. MAIN PIPELINE\n",
        "# ==============================================================================\n",
        "def main():\n",
        "    \"\"\"Main NLP pipeline for Pokemon target classification\"\"\"\n",
        "    print(\"ðŸš€ Pokemon Tactical Strike - NLP Pipeline\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Check device\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"ðŸ”§ Using device: {device}\")\n",
        "\n",
        "    # Clear GPU cache\n",
        "    if device == \"cuda\":\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    MODEL_PATH = \"./pokemon_nlp_model\"\n",
        "\n",
        "    # Check if we already have a trained model\n",
        "    if os.path.exists(MODEL_PATH) and os.path.exists(os.path.join(MODEL_PATH, \"config.json\")):\n",
        "        print(\"âœ… Found existing trained model. Skipping training...\")\n",
        "\n",
        "        # --- 3. Process Test Prompts ---\n",
        "        print(\"\\n[STEP 3/3] Processing Test Prompts...\")\n",
        "\n",
        "        try:\n",
        "            # Load test prompts with encoding error handling\n",
        "            try:\n",
        "                with open(\"test_prompts.json\", 'r', encoding='utf-8') as f:\n",
        "                    test_data = json.load(f)\n",
        "            except UnicodeDecodeError:\n",
        "                # Try different encoding if UTF-8 fails\n",
        "                print(\"âš ï¸  UTF-8 encoding failed, trying latin-1...\")\n",
        "                with open(\"test_prompts.json\", 'r', encoding='latin-1') as f:\n",
        "                    test_data = json.load(f)\n",
        "\n",
        "            test_prompts = [item['prompt'] for item in test_data]\n",
        "            test_image_ids = [item['image_id'] for item in test_data]\n",
        "\n",
        "            print(f\"âœ… Loaded {len(test_prompts)} test prompts\")\n",
        "\n",
        "            # Load the trained model\n",
        "            loaded_tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "            loaded_model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "            # Predict targets\n",
        "            print(\"ðŸ”® Predicting targets for test prompts...\")\n",
        "            predicted_targets = predict_targets(loaded_model, loaded_tokenizer, test_prompts, device=device)\n",
        "\n",
        "            # Create output in the required format\n",
        "            output_data = {\"images\": []}\n",
        "            for image_id, target in zip(test_image_ids, predicted_targets):\n",
        "                # Remove file extension from image_id\n",
        "                image_id_without_ext = image_id.split('.')[0]\n",
        "\n",
        "                # Determine protected classes (all classes except the target)\n",
        "                protected = [c for c in CLASSES if c != target]\n",
        "\n",
        "                output_data[\"images\"].append({\n",
        "                    \"id\": image_id_without_ext,\n",
        "                    \"target\": [target],\n",
        "                    \"protected\": protected\n",
        "                })\n",
        "\n",
        "            # Save output\n",
        "            with open(\"simplified_test_prompts.json\", 'w') as f:\n",
        "                json.dump(output_data, f, indent=2)\n",
        "\n",
        "            print(f\"âœ… Simplified output saved to 'simplified_test_prompts.json'\")\n",
        "            print(f\"ðŸ“Š Sample predictions:\")\n",
        "            for i in range(min(5, len(output_data[\"images\"]))):\n",
        "                print(f\"   {output_data['images'][i]['id']}: target={output_data['images'][i]['target']}, protected={output_data['images'][i]['protected']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing test prompts: {e}\")\n",
        "            # Try to provide more detailed error information\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    else:\n",
        "        # --- 1. Data Preparation ---\n",
        "        print(\"\\n[STEP 1/3] Preparing Training Data...\")\n",
        "\n",
        "        processor = PromptProcessor()\n",
        "\n",
        "        # Load original training data\n",
        "        try:\n",
        "            train_data = processor.load_train_prompts(\"train_prompts.json\")\n",
        "            print(f\"âœ… Loaded {len(train_data)} original training prompts\")\n",
        "        except:\n",
        "            print(\"âš ï¸  Could not load train_prompts.json, using synthetic data only\")\n",
        "            train_data = []\n",
        "\n",
        "        # Generate synthetic data\n",
        "        synthetic_data = processor.generate_synthetic_prompts(num_prompts=10000)\n",
        "        print(f\"âœ… Generated {len(synthetic_data)} synthetic training prompts\")\n",
        "\n",
        "        # Combine data\n",
        "        all_data = train_data + synthetic_data\n",
        "        random.shuffle(all_data)\n",
        "\n",
        "        texts = [item['prompt'] for item in all_data]\n",
        "        labels = [label2id[item['target']] for item in all_data]\n",
        "\n",
        "        # Show class distribution\n",
        "        label_counts = Counter(labels)\n",
        "        print(\"ðŸ“Š Class distribution:\")\n",
        "        for class_id, count in label_counts.items():\n",
        "            print(f\"   {id2label[class_id]}: {count} samples\")\n",
        "\n",
        "        train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "            texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "        )\n",
        "        print(f\"--> Data split into {len(train_texts)} training and {len(val_texts)} validation samples.\")\n",
        "\n",
        "        # --- 2. Model Training ---\n",
        "        print(\"\\n[STEP 2/3] Training NLP Model...\")\n",
        "\n",
        "        MODEL_CHECKPOINT = \"chandar-lab/NeoBERT\"\n",
        "\n",
        "        try:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, trust_remote_code=True)\n",
        "\n",
        "            # Load model\n",
        "            model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                MODEL_CHECKPOINT,\n",
        "                num_labels=len(CLASSES),\n",
        "                id2label=id2label,\n",
        "                label2id=label2id,\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            print(f\"--> Model '{MODEL_CHECKPOINT}' loaded successfully.\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error loading model: {e}\")\n",
        "            return\n",
        "\n",
        "        # Tokenization\n",
        "        print(\"ðŸ”¤ Tokenizing data...\")\n",
        "        train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=1024)\n",
        "        val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=1024)\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = create_data_loader(train_encodings, train_labels, batch_size=4, shuffle=True)\n",
        "        val_loader = create_data_loader(val_encodings, val_labels, batch_size=8, shuffle=False)\n",
        "\n",
        "        print(\"ðŸš€ Starting model training...\")\n",
        "        try:\n",
        "            model = train_model_improved(model, train_loader, val_loader, num_epochs=2, learning_rate=2e-5, device=device)\n",
        "\n",
        "            # Save model and tokenizer\n",
        "            model.save_pretrained(MODEL_PATH)\n",
        "            tokenizer.save_pretrained(MODEL_PATH)\n",
        "            print(f\"âœ… Model training complete. Saved to '{MODEL_PATH}'.\")\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Training failed: {e}\")\n",
        "            return\n",
        "\n",
        "        # --- 3. Process Test Prompts ---\n",
        "        print(\"\\n[STEP 3/3] Processing Test Prompts...\")\n",
        "\n",
        "        try:\n",
        "            # Load test prompts with encoding error handling\n",
        "            try:\n",
        "                with open(\"test_prompts.json\", 'r', encoding='utf-8') as f:\n",
        "                    test_data = json.load(f)\n",
        "            except UnicodeDecodeError:\n",
        "                # Try different encoding if UTF-8 fails\n",
        "                print(\"âš ï¸  UTF-8 encoding failed, trying latin-1...\")\n",
        "                with open(\"test_prompts.json\", 'r', encoding='latin-1') as f:\n",
        "                    test_data = json.load(f)\n",
        "\n",
        "            test_prompts = [item['prompt'] for item in test_data]\n",
        "            test_image_ids = [item['image_id'] for item in test_data]\n",
        "\n",
        "            print(f\"âœ… Loaded {len(test_prompts)} test prompts\")\n",
        "\n",
        "            # Load the trained model\n",
        "            loaded_tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "            loaded_model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
        "\n",
        "            # Predict targets\n",
        "            print(\"ðŸ”® Predicting targets for test prompts...\")\n",
        "            predicted_targets = predict_targets(loaded_model, loaded_tokenizer, test_prompts, device=device)\n",
        "\n",
        "            # Create output in the required format\n",
        "            output_data = {\"images\": []}\n",
        "            for image_id, target in zip(test_image_ids, predicted_targets):\n",
        "                # Remove file extension from image_id\n",
        "                image_id_without_ext = image_id.split('.')[0]\n",
        "\n",
        "                # Determine protected classes (all classes except the target)\n",
        "                protected = [c for c in CLASSES if c != target]\n",
        "\n",
        "                output_data[\"images\"].append({\n",
        "                    \"id\": image_id_without_ext,\n",
        "                    \"target\": [target],\n",
        "                    \"protected\": protected\n",
        "                })\n",
        "\n",
        "            # Save output\n",
        "            with open(\"simplified_test_prompts.json\", 'w') as f:\n",
        "                json.dump(output_data, f, indent=2)\n",
        "\n",
        "            print(f\"âœ… Simplified output saved to 'simplified_test_prompts.json'\")\n",
        "            print(f\"ðŸ“Š Sample predictions:\")\n",
        "            for i in range(min(5, len(output_data[\"images\"]))):\n",
        "                print(f\"   {output_data['images'][i]['id']}: target={output_data['images'][i]['target']}, protected={output_data['images'][i]['protected']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error processing test prompts: {e}\")\n",
        "            # Try to provide more detailed error information\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEeDBMxSEk1D",
        "outputId": "e69104bb-5b61-4092-f312-d53f24d362e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Pokemon Tactical Strike - NLP Pipeline\n",
            "======================================================================\n",
            "ðŸ”§ Using device: cuda\n",
            "âœ… Found existing trained model. Skipping training...\n",
            "\n",
            "[STEP 3/3] Processing Test Prompts...\n",
            "âš ï¸  UTF-8 encoding failed, trying latin-1...\n",
            "âœ… Loaded 200 test prompts\n",
            "ðŸ”® Predicting targets for test prompts...\n",
            "âœ… Simplified output saved to 'simplified_test_prompts.json'\n",
            "ðŸ“Š Sample predictions:\n",
            "   img_00000: target=['pikachu'], protected=['charizard', 'bulbasaur', 'mewtwo']\n",
            "   img_00001: target=['charizard'], protected=['pikachu', 'bulbasaur', 'mewtwo']\n",
            "   img_00002: target=['bulbasaur'], protected=['pikachu', 'charizard', 'mewtwo']\n",
            "   img_00003: target=['charizard'], protected=['pikachu', 'bulbasaur', 'mewtwo']\n",
            "   img_00004: target=['mewtwo'], protected=['pikachu', 'charizard', 'bulbasaur']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "MOUNTPOINT = '/content/gdrive'\n",
        "DATADIR = os.path.join(MOUNTPOINT, 'My Drive', 'myfolder')\n",
        "drive.mount(MOUNTPOINT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUsuV_NjessS",
        "outputId": "cb536aa7-5938-441b-aa3c-a67a481f3553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    }
  ]
}